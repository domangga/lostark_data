{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dfa1c60",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (Temp/ipykernel_5688/741630286.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_5688/741630286.py\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    columns = row.find_all(\"td,class=d-none d-lg-table-cell')\u001b[0m\n\u001b[1;37m                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_character_names_from_page(url):\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    rank_rows = soup.find_all(\"tr\")\n",
    "    character_names = []\n",
    "\n",
    "    for row in rank_rows:\n",
    "        columns = row.find_all(\"td\")\n",
    "        if len(columns) > 1:\n",
    "            character_name = columns[1].get_text(strip=True)\n",
    "            character_names.append(character_name)\n",
    "    \n",
    "    return character_names\n",
    "\n",
    "# 두 페이지의 URL\n",
    "urls = [\n",
    "    'https://loawa.com/rank'    \n",
    "]\n",
    "\n",
    "all_character_names = []\n",
    "for url in urls:\n",
    "    all_character_names.extend(get_character_names_from_page(url))\n",
    "\n",
    "# 상위 50개만 선택\n",
    "top_50_character_names = all_character_names[:50]\n",
    "\n",
    "# 파일에 저장\n",
    "with open('Save_Crawling.txt', 'w', encoding='UTF-8') as file:\n",
    "    for name in top_50_character_names:\n",
    "        file.write(name + '\\n')\n",
    "\n",
    "print(\"저장이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a93b1100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "# 홈페이지 주소 가져오기\n",
    "url = \"https://loawa.com/rank\"\n",
    "\n",
    "html = requests.get(url)\n",
    "bs_html = BeautifulSoup(html.content, \"html.parser\")\n",
    "\n",
    "value = soup.find(\"tbody\")\n",
    "print(value)\n",
    "\n",
    "sys.stdout = open('Save_Crawlings.txt', 'w', encoding='UTF-8')\n",
    "\n",
    "print(value) # 웹 페이지 txt 파일로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f4cfac0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expression cannot contain assignment, perhaps you meant \"==\"? (Temp/ipykernel_5688/1224531434.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_5688/1224531434.py\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    rank_row = soup.find(\"tbody\", data-container_=\"list\")\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expression cannot contain assignment, perhaps you meant \"==\"?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 1) requests 라이브러리를 활용한 HTML 페이지 요청\n",
    "res = requests.get('https://loawa.com/rank')\n",
    "\n",
    "# 2) HTML 페이지 파싱\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "# 3) 필요한 데이터 검색\n",
    "rank_row = soup.find(\"tbody\",data-container=\"list\")\n",
    "\n",
    "# 4) 필요한 데이터 추출 및 파일에 저장\n",
    "if rank_row:\n",
    "    # \"흰여울의은월\" 텍스트가 포함된 열 찾기\n",
    "    columns = rank_row.find_all(\"tr\")\n",
    "    # 예를 들어, 2번째 열에 텍스트가 있다고 가정\n",
    "    character_name = columns[1].get_text(strip=True) if len(columns) > 1 else \"데이터를 찾을 수 없습니다.\"\n",
    "else:\n",
    "    character_name = \"데이터를 찾을 수 없습니다.\"\n",
    "\n",
    "with open('Save_Crawling.txt', 'w', encoding='UTF-8') as file:\n",
    "    file.write(character_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d474c4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 1) requests 라이브러리를 활용한 HTML 페이지 요청\n",
    "res = requests.get('https://maplestory.nexon.com/N23Ranking/World/Total?w=15')\n",
    "\n",
    "# 2) HTML 페이지 파싱\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "# 3) 필요한 데이터 검색\n",
    "rank_row = soup.find(\"tr\", class_=\"rank01\")\n",
    "\n",
    "# 4) 필요한 데이터 추출 및 파일에 저장\n",
    "if rank_row:\n",
    "    # \"흰여울의은월\" 텍스트가 포함된 열 찾기\n",
    "    columns = rank_row.find_all(\"td\")\n",
    "    # 예를 들어, 2번째 열에 텍스트가 있다고 가정\n",
    "    character_name = columns[1].get_text(strip=True) if len(columns) > 1 else \"데이터를 찾을 수 없습니다.\"\n",
    "else:\n",
    "    character_name = \"데이터를 찾을 수 없습니다.\"\n",
    "\n",
    "with open('Save_Crawling.txt', 'w', encoding='UTF-8') as file:\n",
    "    file.write(character_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4132cd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_character_names_from_page(url):\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    rank_rows = soup.find_all(\"tr\")\n",
    "    character_names = []\n",
    "\n",
    "    for row in rank_rows:\n",
    "        columns = row.find_all(\"td\")\n",
    "        if len(columns) > 1:\n",
    "            character_name = columns[1].get_text(strip=True)\n",
    "            character_names.append(character_name)\n",
    "    \n",
    "    return character_names\n",
    "\n",
    "# 두 페이지의 URL\n",
    "urls = [\n",
    "    'https://loawa.com/rank'    \n",
    "]\n",
    "\n",
    "all_character_names = []\n",
    "for url in urls:\n",
    "    all_character_names.extend(get_character_names_from_page(url))\n",
    "\n",
    "# 상위 50개만 선택\n",
    "top_50_character_names = all_character_names[:50]\n",
    "\n",
    "# 파일에 저장\n",
    "with open('Save_Crawling.txt', 'w', encoding='UTF-8') as file:\n",
    "    for name in top_50_character_names:\n",
    "        file.write(name + '\\n')\n",
    "\n",
    "print(\"저장이 완료되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
